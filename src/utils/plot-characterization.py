#!/usr/bin/env python3

# Author: August Ning (auguning@amd.com)
# Modified by: Daniel Chang (daniel.chang@amd.com)
# Last Updated: 01/29/24
# Summer 2023 Co-op project for RIKEN Fugaku-Next
# This script uses the CSV file generated by the workload-characteriztion.py script and creates two figures. One
# that shows the end-to-end timing (e2e_time.pdf) for the CPU and GPU and another that shows the GPU kernel's
# bottlenecks (gpu_time.pdf).

import matplotlib.pyplot as plt
import matplotlib.patches as mpatches
import pandas as pd
plt.rcParams['figure.figsize'] = [20, 8]
plt.rcParams['font.size'] = 24

# This needs to be changed to the CSV filename that was generated by the workload-characterization.py script
FILENAME = 'MY_FILENAME.csv'

data_df = pd.read_csv(FILENAME)
GRAPH_NAME = FILENAME.replace(".csv", "")

################## Plot End-to-End Analysis ##################
# This portion of code will graph the end-to-end CPU/GPU timing breakdown
fig, ax = plt.subplots()
width = 0.5
colors = ["#2e8b57","#ffa500","#1e90ff","#0000ff","#00ff00", "#ff1493"]
# iterate over the number of GPUs in the system
for row_idx in range(data_df.shape[0]):
    base = 0
    color_idx = 0
    # for calculating cpu time, take omnitrace total trace time
    # and subtract gpu time, communication time, and cold invoke time
    # note: depending on omnitrace bugs, you may want to use 
    # omniperf's gpu runtime and/or gpu-gpu communication time
    cpu_time = data_df['ot_total_trace_time'][row_idx] - \
        data_df['op_gpu_time'][row_idx] - \
        data_df['ot_host_device_time'][row_idx] - \
        data_df['ot_device_host_time'][row_idx] - \
        data_df['op_gpu_gpu_comm_time'][row_idx] - \
        data_df['ot_invoke_time'][row_idx]

    ax.barh(row_idx, cpu_time, width, left=base, color=colors[color_idx])
    base += cpu_time
    color_idx += 1

    ax.barh(row_idx, data_df['ot_host_device_time'][row_idx], width, left=base, color=colors[color_idx])
    base += data_df['ot_host_device_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_device_host_time'][row_idx], width, left=base, color=colors[color_idx])
    base += data_df['ot_device_host_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['op_gpu_gpu_comm_time'][row_idx], width, left=base, color=colors[color_idx])
    base += data_df['op_gpu_gpu_comm_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_invoke_time'][row_idx], width, left=base, color=colors[color_idx])
    base += data_df['ot_invoke_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['op_gpu_time'][row_idx], width, left=base, color=colors[color_idx])
    base += data_df['op_gpu_time'][row_idx]

plt.yticks(list(range(data_df.shape[0])), labels=[f'GPU {data_df["gpu_id"][idx]}' for idx in range(data_df.shape[0])])
plt.ylabel('GPU ID')
plt.xlabel('Runtime (ns)')
plt.title('E2E Runtime Classification: CPU, GPU, Communication')
legend_labels = ['CPU', 'Host To Device', 'Device to Host', 'GPU-GPU', 'Invoke Overhead', 'GPU']
ax.legend(handles=[mpatches.Patch(color=colors[i], label=legend_labels[i]) for i in range(len(legend_labels))])

plt.savefig(GRAPH_NAME + '-e2e_time.pdf', bbox_inches='tight')

################## Plot GPU bottleneck analysis ##################
# This portion of code will plot the GPU kernel's bottlenecks
fig, ax = plt.subplots()

# since we're stacking over multiple for loops, keep track of a base per GPU
bases = [0 for _ in range(data_df.shape[0])]

# we need 3 for loops:
# one for the no flop time
# one for underperforming kernels (< 80% percentage of peak threshold)
# one for above threshold kernels (> 80% percentage of peak threshold)
for row_idx in range(data_df.shape[0]):
    color_idx = 0

    ax.barh(row_idx, data_df['ot_above_util_lds_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx])
    bases[row_idx] += data_df['ot_above_util_lds_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_above_util_gl1_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx])
    bases[row_idx] += data_df['ot_above_util_gl1_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_above_util_gl2_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx])
    bases[row_idx] += data_df['ot_above_util_gl2_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_above_util_hbm_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx])
    bases[row_idx] += data_df['ot_above_util_hbm_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_above_util_valu_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx])
    bases[row_idx] += data_df['ot_above_util_valu_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_above_util_mfma_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx])
    bases[row_idx] += data_df['ot_above_util_mfma_time'][row_idx]
    color_idx += 1

    plt.vlines(bases[row_idx], ymin=row_idx-0.4, ymax=row_idx+0.4, colors='black', linewidth=5.0)

for row_idx in range(data_df.shape[0]):
    color_idx = 0

    ax.barh(row_idx, data_df['ot_under_util_lds_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='/')
    bases[row_idx] += data_df['ot_under_util_lds_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_under_util_gl1_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='/')
    bases[row_idx] += data_df['ot_under_util_gl1_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_under_util_gl2_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='/')
    bases[row_idx] += data_df['ot_under_util_gl2_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_under_util_hbm_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='/')
    bases[row_idx] += data_df['ot_under_util_hbm_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_under_util_valu_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='/')
    bases[row_idx] += data_df['ot_under_util_valu_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_under_util_mfma_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='/')
    bases[row_idx] += data_df['ot_under_util_mfma_time'][row_idx]
    color_idx += 1

    plt.vlines(bases[row_idx], ymin=row_idx-0.4, ymax=row_idx+0.4, colors='black', linewidth=5.0)

for row_idx in range(data_df.shape[0]):
    color_idx = 0

    ax.barh(row_idx, data_df['ot_no_flops_lds_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='X')
    bases[row_idx] += data_df['ot_no_flops_lds_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_no_flops_gl1_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='X')
    bases[row_idx] += data_df['ot_no_flops_gl1_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_no_flops_gl2_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='X')
    bases[row_idx] += data_df['ot_no_flops_gl2_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_no_flops_hbm_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='X')
    bases[row_idx] += data_df['ot_no_flops_hbm_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_no_flops_valu_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='X')
    bases[row_idx] += data_df['ot_no_flops_valu_time'][row_idx]
    color_idx += 1

    ax.barh(row_idx, data_df['ot_no_flops_mfma_time'][row_idx], width, left=bases[row_idx], color=colors[color_idx], hatch='X')
    bases[row_idx] += data_df['ot_no_flops_mfma_time'][row_idx]
    color_idx += 1

plt.yticks(list(range(data_df.shape[0])), labels=[f'GPU {data_df["gpu_id"][idx]}' for idx in range(data_df.shape[0])])
plt.ylabel('GPU ID')
plt.xlabel('Runtime (ns)')
plt.title('GPU Kernel Runtime Breakdowns by Bottlenecks and Performance')

# Had to create the legend manually so as to include the / and X hatch marks.
legend_LDS = mpatches.Patch(color=colors[0], label='LDS BW')
legend_GL1 = mpatches.Patch(color=colors[1], label='GL1 BW')
legend_GL2 = mpatches.Patch(color=colors[2], label='GL2 BW')
legend_HBM = mpatches.Patch(color=colors[3], label='HBM BW')
legend_VALU = mpatches.Patch(color=colors[4], label='VALU Compute')
legend_MFMA = mpatches.Patch(color=colors[5], label='MFMA Compute')
legend_blank = mpatches.Patch(facecolor='white', edgecolor='black', label='Above Threshold')
legend_slash = mpatches.Patch(facecolor='white', edgecolor='black', hatch='/', label='Below Threshold')
legend_Xmark = mpatches.Patch(facecolor='white', edgecolor='black', hatch='X', label='No FLOPs')
ax.legend(handles=[legend_LDS, legend_GL1, legend_GL2, legend_HBM, legend_VALU, legend_MFMA, legend_blank, legend_slash, legend_Xmark], loc='best')

plt.savefig(GRAPH_NAME + '-gpu_time.pdf', bbox_inches='tight')

