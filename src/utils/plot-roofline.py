#!/usr/bin/env python3

# Author: August Ning (auguning@amd.com)
# Modified by: Daniel Chang (daniecha@amd.com)
# Last Updated: 01/31/24
# This script uses the roofline.csv file generated by Omniperf to generate an interactive hierarchical roofline plot.
# To use the script, use the OMNIPERF_DB_FOLDER_NAME variable at the bottom of the file to point it to the
# folder containing your omniperf files roofline.csv and pmc_perf.csv
# The code uses a heavily modified version of the functions used to graph rooflines in Omniperf. Modifications were
# made to graph a kernel's LDS points and also show more kernels.

import os
import pandas as pd
from collections import OrderedDict
import numpy as np
import matplotlib.pyplot as plt
from tqdm import tqdm
import sys
import time

from dataclasses import dataclass
import csv

from dash import html, dash_table

from dash import dcc
import plotly.graph_objects as go

SYMBOLS = [0, 1, 2, 3, 4, 5, 13, 17, 18, 20]

################################################
# Global vars
################################################

IMGNAME = "empirRoof"

L2_BANKS = 32  # default assuming mi200

XMIN = 0.0
XMAX = 1000000

FONT_SIZE = 16
FONT_COLOR = "black"
FONT_WEIGHT = "bold"

SUPPORTED_SOC = ["mi200"]

# Use this variable to change how many of the top X kernels you want to graph. By default, Omniperf only graphs the
# Top 10 kernels.
TOP_N = 20

##### Default folder to place omniperf folders in and the two CSV files #####
OMNIPERF_DB_BASE='omniperf'
PMC_PERF_FILE='pmc_perf.csv'
ROOFLINE_DATA_FILE = 'roofline.csv'

################################################
# Helper funcs
################################################
@dataclass
class AI_Data:
    KernelName: str
    numCalls: float

    total_flops: float
    valu_flops: float
    mfma_flops_f16: float
    mfma_flops_bf16: float
    mfma_flops_f32: float
    mfma_flops_f64: float
    mfma_iops_i8: float
    lds_data: float
    L1cache_data: float
    L2cache_data: float
    hbm_data: float

    totalDuration: float
    avgDuration: float


def get_font():
    return {
        "size": FONT_SIZE,
        "color": FONT_COLOR,
        "weight": FONT_WEIGHT,
        "family": "serif",
    }

def get_color(catagory):
    if catagory == "ai_l1":
        return "green"
    elif catagory == "ai_l2":
        return "blue"
    elif catagory == "ai_hbm":
        return "red"
    elif catagory == "ai_lds":
        return "purple"
    else:
        raise RuntimeError("Invalid category passed to get_color()")

def to_int(a):
    if str(type(a)) == "<class 'NoneType'>":
        return np.nan
    else:
        return int(a)

def generate_plots(
    roof_info, ai_data, mem_level, is_standalone, kernel_names, verbose, fig=None
):
    if fig is None:
        fig = go.Figure()
    plotMode = "lines+text" if is_standalone else "lines"
    line_data = empirical_roof(roof_info, mem_level, verbose)
    if verbose:
        print("Line data:\n", line_data)

    #######################
    # Plot BW Lines
    #######################
    if mem_level == "ALL":
        cacheHierarchy = ["HBM", "L2", "L1", "LDS"]
    else:
        cacheHierarchy = mem_level

    for cacheLevel in cacheHierarchy:
        fig.add_trace(
            go.Scatter(
                x=line_data[cacheLevel.lower()][0],
                y=line_data[cacheLevel.lower()][1],
                name="{}-{}".format(cacheLevel, roof_info["dtype"]),
                mode=plotMode,
                hovertemplate="<b>%{text}</b>",
                text=[
                    "{} GB/s".format(to_int(line_data[cacheLevel.lower()][2])),
                    None
                    if is_standalone
                    else "{} GB/s".format(to_int(line_data[cacheLevel.lower()][2])),
                ],
                textposition="top right",
            )
        )

    if roof_info["dtype"] != "FP16" and roof_info["dtype"] != "I8":
        fig.add_trace(
            go.Scatter(
                x=line_data["valu"][0],
                y=line_data["valu"][1],
                name="Peak VALU-{}".format(roof_info["dtype"]),
                mode=plotMode,
                hovertemplate="<b>%{text}</b>",
                text=[
                    None
                    if is_standalone
                    else "{} GFLOP/s".format(to_int(line_data["valu"][2])),
                    "{} GFLOP/s".format(to_int(line_data["valu"][2])),
                ],
                textposition="top left",
            )
        )

    if roof_info["dtype"] == "FP16":
        pos = "bottom left"
    else:
        pos = "top left"
    fig.add_trace(
        go.Scatter(
            x=line_data["mfma"][0],
            y=line_data["mfma"][1],
            name="Peak MFMA-{}".format(roof_info["dtype"]),
            mode=plotMode,
            hovertemplate="<b>%{text}</b>",
            text=[
                None
                if is_standalone
                else "{} GFLOP/s".format(to_int(line_data["mfma"][2])),
                "{} GFLOP/s".format(to_int(line_data["mfma"][2])),
            ],
            textposition=pos,
        )
    )
    #######################
    # Plot Application AI
    #######################
    if roof_info["dtype"] != "I8":
        fig.add_trace(
            go.Scatter(
                x=ai_data["ai_l1"][0],
                y=ai_data["ai_l1"][1],
                name="ai_l1",
                mode="markers",
                marker={"color": "#00CC96"},
                marker_symbol=SYMBOLS if kernel_names else None,
            )
        )
        fig.add_trace(
            go.Scatter(
                x=ai_data["ai_l2"][0],
                y=ai_data["ai_l2"][1],
                name="ai_l2",
                mode="markers",
                marker={"color": "#EF553B"},
                marker_symbol=SYMBOLS if kernel_names else None,
            )
        )
        fig.add_trace(
            go.Scatter(
                x=ai_data["ai_hbm"][0],
                y=ai_data["ai_hbm"][1],
                name="ai_hbm",
                mode="markers",
                marker={"color": "#636EFA"},
                marker_symbol=SYMBOLS if kernel_names else None,
            )
        )
        fig.add_trace(
            go.Scatter(
                x=ai_data["ai_lds"][0],
                y=ai_data["ai_lds"][1],
                name="ai_lds",
                mode="markers",
                marker={"color": "#AD00CC"},
                marker_symbol=SYMBOLS if kernel_names else None,
            )
        )
    fig.update_layout(
        xaxis_title="Arithmetic Intensity (FLOPs/Byte)",
        yaxis_title="Performance (GFLOP/sec)",
        hovermode="x unified",
        margin=dict(l=50, r=50, b=50, t=50, pad=4),
    )
    fig.update_xaxes(type="log", autorange=True)
    fig.update_yaxes(type="log", autorange=True)
    return fig


def get_roofline(
    path_to_dir,
    ret_df,
    verbose,
    dev_id=None,
    sort_type="kernels",
    mem_level="ALL",
    kernel_names=True,
    is_standalone=True,
):
    if kernel_names and (not is_standalone):
        print("ERROR: --roof-only is required for --kernel-names")
        sys.exit(1)

    # Roofline settings
    fp32_details = {
        "path": path_to_dir,
        "sort": sort_type,
        "device": 0,
        "dtype": "FP32",
    }
    fp16_details = {
        "path": path_to_dir,
        "sort": sort_type,
        "device": 0,
        "dtype": "FP16",
    }
    int8_details = {"path": path_to_dir, "sort": sort_type, "device": 0, "dtype": "I8"}

    # Generate roofline plots
    print("Path: ", path_to_dir)
    ai_data = plot_application(sort_type, ret_df, verbose)
    if verbose >= 1:
        # print AI data for each mem level
        print("AI at each mem level")
        for i in ai_data:
            print(i, "->", ai_data[i])
        print("\n")

    fp32_fig = generate_plots(
        fp32_details, ai_data, mem_level, is_standalone, kernel_names, verbose
    )
    fp16_fig = generate_plots(
        fp16_details, ai_data, mem_level, is_standalone, kernel_names, verbose
    )
    ml_combo_fig = generate_plots(
        int8_details, ai_data, mem_level, is_standalone, kernel_names, verbose, fp16_fig
    )

    legend = go.Figure(
        go.Scatter(
            mode="markers",
            x=[0] * 10,
            y=ai_data["kernelNames"],
            marker_symbol=SYMBOLS,
            marker_size=15,
        )
    )

    legend.update_layout(
        title="Kernel Names and Markers",
        margin=dict(b=0, r=0),
        xaxis_range=[-1, 1],
        xaxis_side="top",
        yaxis_side="right",
        height=400,
        width=1000,
    )
    legend.update_xaxes(dtick=1)

    if is_standalone:
        dev_id = "ALL" if dev_id == -1 else str(dev_id)

        fp32_fig.write_html(OMNIPERF_DB_FOLDER_NAME + "-empirRoof_gpu-{}_fp32.html".format(dev_id))
        ml_combo_fig.write_html(
            OMNIPERF_DB_FOLDER_NAME + "-empirRoof_gpu-{}_int8_fp16.html".format(dev_id)
        )

        if kernel_names:
            # only save a legend if kernel_names option is toggled
            legend.write_html("kernelName_legend.html")
        time.sleep(1)
        # Re-save to remove loading MathJax pop up
        fp32_fig.write_html(OMNIPERF_DB_FOLDER_NAME + "-empirRoof_gpu-{}_fp32.html".format(dev_id))
        ml_combo_fig.write_html(
            OMNIPERF_DB_FOLDER_NAME + "-empirRoof_gpu-{}_int8_fp16.html".format(dev_id)
        )
        if kernel_names:
            legend.write_html("kernelName_legend.html")
        print("Empirical Roofline PDFs saved!")
    else:
        return html.Section(
            id="roofline",
            children=[
                html.Div(
                    className="float-container",
                    children=[
                        html.Div(
                            className="float-child",
                            children=[
                                html.H3(
                                    children="Empirical Roofline Analysis (FP32/FP64)"
                                ),
                                dcc.Graph(figure=fp32_fig),
                            ],
                        ),
                        html.Div(
                            className="float-child",
                            children=[
                                html.H3(
                                    children="Empirical Roofline Analysis (FP16/INT8)"
                                ),
                                dcc.Graph(figure=ml_combo_fig),
                            ],
                        ),
                    ],
                )
            ],
        )

# -------------------------------------------------------------------------------------
#                           Plot BW at each cache level
# -------------------------------------------------------------------------------------
def plot_roof(roof_details, roof_data, mem_level, verbose):
    # TODO: This is where filtering by memory level will need to occur for standalone
    graphPoints = {"hbm": [], "l2": [], "l1": [], "lds": [], "valu": [], "mfma": []}

    if mem_level == "ALL":
        cacheHierarchy = ["HBM", "L2", "L1", "LDS"]
    else:
        cacheHierarchy = mem_level

    x1 = y1 = x2 = y2 = -1
    x1_mfma = y1_mfma = x2_mfma = y2_mfma = -1
    target_precision = roof_details["dtype"][2:]

    if roof_details["dtype"] != "FP16" and roof_details["dtype"] != "I8":
        peakOps = float(
            roof_data[roof_details["dtype"] + "Flops"][roof_details["device"]]
        )
    for i in range(0, len(cacheHierarchy)):
        # Plot BW line
        if verbose >= 3:
            print("Current cache level is ", cacheHierarchy[i])
        curr_bw = cacheHierarchy[i] + "Bw"
        peakBw = float(roof_data[curr_bw][roof_details["device"]])

        if roof_details["dtype"] == "I8":
            peakMFMA = float(roof_data["MFMAI8Ops"][roof_details["device"]])
        else:
            peakMFMA = float(
                roof_data["MFMAF{}Flops".format(target_precision)][roof_details["device"]]
            )

        x1 = float(XMIN)
        y1 = float(XMIN) * peakBw
        # Note: No reg peakOps for FP16 or INT8
        if roof_details["dtype"] != "FP16" and roof_details["dtype"] != "I8":
            x2 = peakOps / peakBw
            y2 = peakOps

            # Plot MFMA lines (NOTE: Assuming MI200 soc)
            x1_mfma = peakOps / peakBw
            y1_mfma = peakOps

        x2_mfma = peakMFMA / peakBw
        y2_mfma = peakMFMA

        # These are the points to use:
        if verbose >= 3:
            print("x = [{}, {}]".format(x1, x2_mfma))
            print("y = [{}, {}]".format(y1, y2_mfma))

        graphPoints[cacheHierarchy[i].lower()].append([x1, x2_mfma])
        graphPoints[cacheHierarchy[i].lower()].append([y1, y2_mfma])
        graphPoints[cacheHierarchy[i].lower()].append(peakBw)

    # -------------------------------------------------------------------------------------
    #                                     Plot computing roof
    # -------------------------------------------------------------------------------------
    # Note: No FMA roof for FP16 or INT8
    if roof_details["dtype"] != "FP16" and roof_details["dtype"] != "I8":
        # Plot FMA roof
        x0 = XMAX
        if x2 < x0:
            x0 = x2

        if verbose >= 3:
            print("FMA ROOF [{}, {}], [{},{}]".format(x0, XMAX, peakOps, peakOps))
        graphPoints["valu"].append([x0, XMAX])
        graphPoints["valu"].append([peakOps, peakOps])
        graphPoints["valu"].append(peakOps)

    # Plot MFMA roof
    if (
        x1_mfma != -1 or roof_details["dtype"] == "FP16" or roof_details["dtype"] == "I8"
    ):  # assert that mfma has been assigned
        x0_mfma = XMAX
        if x2_mfma < x0_mfma:
            x0_mfma = x2_mfma

        if verbose >= 3:
            print("MFMA ROOF [{}, {}], [{},{}]".format(x0_mfma, XMAX, peakMFMA, peakMFMA))
        graphPoints["mfma"].append([x0_mfma, XMAX])
        graphPoints["mfma"].append([peakMFMA, peakMFMA])
        graphPoints["mfma"].append(peakMFMA)

    return graphPoints

# -------------------------------------------------------------------------------------
#                              Overlay application performance
# -------------------------------------------------------------------------------------
# Calculate relevant metrics for ai calculation
def plot_application(sortType, ret_df, verbose):
    df = ret_df["pmc_perf"]
    # Sort by top kernels or top dispatches?
    df = df.sort_values(by=["KernelName"])
    df = df.reset_index(drop=True)

    total_flops = (
        valu_flops
    ) = (
        mfma_flops_bf16
    ) = (
        mfma_flops_f16
    ) = (
        mfma_iops_i8
    ) = (
        mfma_flops_f32
    ) = (
        mfma_flops_f64
    ) = (
        lds_data
    ) = L1cache_data = L2cache_data = hbm_data = calls = totalDuration = avgDuration = 0.0

    kernelName = ""

    myList = []
    at_end = False
    next_kernelName = ""

    for idx in df.index:
        # CASE: Top kernels
        # Calculate + append AI data if
        # a) current KernelName is different than previous OR
        # b) We've reached the end of list
        if idx + 1 == df.shape[0]:
            at_end = True
        else:
            next_kernelName = df["KernelName"][idx + 1]

        kernelName = df["KernelName"][idx]
        try:
            total_flops += (
                (
                    64
                    * (
                        df["SQ_INSTS_VALU_ADD_F16"][idx]
                        + df["SQ_INSTS_VALU_MUL_F16"][idx]
                        + (2 * df["SQ_INSTS_VALU_FMA_F16"][idx])
                        + df["SQ_INSTS_VALU_TRANS_F16"][idx]
                    )
                )
                + (
                    64
                    * (
                        df["SQ_INSTS_VALU_ADD_F32"][idx]
                        + df["SQ_INSTS_VALU_MUL_F32"][idx]
                        + (2 * df["SQ_INSTS_VALU_FMA_F32"][idx])
                        + df["SQ_INSTS_VALU_TRANS_F32"][idx]
                    )
                )
                + (
                    64
                    * (
                        df["SQ_INSTS_VALU_ADD_F64"][idx]
                        + df["SQ_INSTS_VALU_MUL_F64"][idx]
                        + (2 * df["SQ_INSTS_VALU_FMA_F64"][idx])
                        + df["SQ_INSTS_VALU_TRANS_F64"][idx]
                    )
                )
                + (df["SQ_INSTS_VALU_MFMA_MOPS_F16"][idx] * 512)
                + (df["SQ_INSTS_VALU_MFMA_MOPS_BF16"][idx] * 512)
                + (df["SQ_INSTS_VALU_MFMA_MOPS_F32"][idx] * 512)
                + (df["SQ_INSTS_VALU_MFMA_MOPS_F64"][idx] * 512)
            )
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped total_flops at index {}".format(kernelName[:35], idx))
            pass
        try:
            valu_flops += (
                64
                * (
                    df["SQ_INSTS_VALU_ADD_F16"][idx]
                    + df["SQ_INSTS_VALU_MUL_F16"][idx]
                    + (2 * df["SQ_INSTS_VALU_FMA_F16"][idx])
                    + df["SQ_INSTS_VALU_TRANS_F16"][idx]
                )
                + 64
                * (
                    df["SQ_INSTS_VALU_ADD_F32"][idx]
                    + df["SQ_INSTS_VALU_MUL_F32"][idx]
                    + (2 * df["SQ_INSTS_VALU_FMA_F32"][idx])
                    + df["SQ_INSTS_VALU_TRANS_F32"][idx]
                )
                + 64
                * (
                    df["SQ_INSTS_VALU_ADD_F64"][idx]
                    + df["SQ_INSTS_VALU_MUL_F64"][idx]
                    + (2 * df["SQ_INSTS_VALU_FMA_F64"][idx])
                    + df["SQ_INSTS_VALU_TRANS_F64"][idx]
                )
            )
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped valu_flops at index {}".format(kernelName[:35], idx))
            pass

        try:
            mfma_flops_f16 += df["SQ_INSTS_VALU_MFMA_MOPS_F16"][idx] * 512
            mfma_flops_bf16 += df["SQ_INSTS_VALU_MFMA_MOPS_BF16"][idx] * 512
            mfma_flops_f32 += df["SQ_INSTS_VALU_MFMA_MOPS_F32"][idx] * 512
            mfma_flops_f64 += df["SQ_INSTS_VALU_MFMA_MOPS_F64"][idx] * 512
            mfma_iops_i8 += df["SQ_INSTS_VALU_MFMA_MOPS_I8"][idx] * 512
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped mfma ops at index {}".format(kernelName[:35], idx))
            pass

        try:
            lds_data += (
                (df["SQ_LDS_IDX_ACTIVE"][idx] - df["SQ_LDS_BANK_CONFLICT"][idx])
                * 4
                * L2_BANKS
            )  # L2_BANKS = 32 (since assuming mi200)
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped lds_data at index {}".format(kernelName[:35], idx))
            pass

        try:
            L1cache_data += df["TCP_TOTAL_CACHE_ACCESSES_sum"][idx] * 64
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped L1cache_data at index {}".format(kernelName[:35], idx))
            pass

        try:
            L2cache_data += (
                df["TCP_TCC_WRITE_REQ_sum"][idx] * 64
                + df["TCP_TCC_ATOMIC_WITH_RET_REQ_sum"][idx] * 64
                + df["TCP_TCC_ATOMIC_WITHOUT_RET_REQ_sum"][idx] * 64
                + df["TCP_TCC_READ_REQ_sum"][idx] * 64
            )
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped L2cache_data at index {}".format(kernelName[:35], idx))
            pass
        try:
            hbm_data += (
                (df["TCC_EA_RDREQ_32B_sum"][idx] * 32)
                + ((df["TCC_EA_RDREQ_sum"][idx] - df["TCC_EA_RDREQ_32B_sum"][idx]) * 64)
                + (df["TCC_EA_WRREQ_64B_sum"][idx] * 64)
                + ((df["TCC_EA_WRREQ_sum"][idx] - df["TCC_EA_WRREQ_64B_sum"][idx]) * 32)
            )
        except KeyError:
            if verbose >= 3:
                print("{}: Skipped hbm_data at index {}".format(kernelName[:35], idx))
            pass

        totalDuration += df["EndNs"][idx] - df["BeginNs"][idx]

        avgDuration += df["EndNs"][idx] - df["BeginNs"][idx]

        calls += 1

        if sortType == "kernels" and (at_end == True or (kernelName != next_kernelName)):
            myList.append(
                AI_Data(
                    kernelName,
                    calls,
                    total_flops / calls,
                    valu_flops / calls,
                    mfma_flops_f16 / calls,
                    mfma_flops_bf16 / calls,
                    mfma_flops_f32 / calls,
                    mfma_flops_f64 / calls,
                    mfma_iops_i8 / calls,
                    lds_data / calls,
                    L1cache_data / calls,
                    L2cache_data / calls,
                    hbm_data / calls,
                    totalDuration,
                    avgDuration / calls,
                )
            )
            if verbose >= 2:
                print(
                    "Just added {} to AI_Data at index {}. # of calls: {}".format(
                        kernelName, idx, calls
                    )
                )
            total_flops = (
                valu_flops
            ) = (
                mfma_flops_bf16
            ) = (
                mfma_flops_f16
            ) = (
                mfma_iops_i8
            ) = (
                mfma_flops_f32
            ) = (
                mfma_flops_f64
            ) = (
                lds_data
            ) = (
                L1cache_data
            ) = L2cache_data = hbm_data = calls = totalDuration = avgDuration = 0.0

        if sortType == "dispatches":
            myList.append(
                AI_Data(
                    kernelName,
                    calls,
                    total_flops,
                    valu_flops,
                    mfma_flops_f16,
                    mfma_flops_bf16,
                    mfma_flops_f32,
                    mfma_flops_f64,
                    mfma_iops_i8,
                    lds_data,
                    L1cache_data,
                    L2cache_data,
                    hbm_data,
                    totalDuration,
                    avgDuration,
                )
            )
            total_flops = (
                valu_flops
            ) = (
                mfma_flops_bf16
            ) = (
                mfma_flops_f16
            ) = (
                mfma_iops_i8
            ) = (
                mfma_flops_f32
            ) = (
                mfma_flops_f64
            ) = (
                lds_data
            ) = (
                L1cache_data
            ) = L2cache_data = hbm_data = calls = totalDuration = avgDuration = 0.0

    myList.sort(key=lambda x: x.totalDuration, reverse=True)

    # print("Top 5 intensities ('{}')...".format(roof_details["sort"]))
    intensities = {"ai_lds": [], "ai_l1": [], "ai_l2": [], "ai_hbm": []}
    curr_perf = []
    kernelNames = []
    i = 0
    # Create list of top N intensities
    while i < TOP_N and i != len(myList):
        kernelNames.append(myList[i].KernelName)
        intensities["ai_lds"].append(
            myList[i].total_flops / myList[i].lds_data
        ) if myList[i].lds_data else intensities["ai_lds"].append(0)
        intensities["ai_l1"].append(
            myList[i].total_flops / myList[i].L1cache_data
        ) if myList[i].L1cache_data else intensities["ai_l1"].append(0)
        # print("cur_ai_L1", myList[i].total_flops/myList[i].L1cache_data) if myList[i].L1cache_data else print("null")
        # print()
        intensities["ai_l2"].append(
            myList[i].total_flops / myList[i].L2cache_data
        ) if myList[i].L2cache_data else intensities["ai_l2"].append(0)
        # print("cur_ai_L2", myList[i].total_flops/myList[i].L2cache_data) if myList[i].L2cache_data else print("null")
        # print()
        intensities["ai_hbm"].append(
            myList[i].total_flops / myList[i].hbm_data
        ) if myList[i].hbm_data else intensities["ai_hbm"].append(0)
        # print("cur_ai_hbm", myList[i].total_flops/myList[i].hbm_data) if myList[i].hbm_data else print("null")
        # print()
        curr_perf.append(myList[i].total_flops / myList[i].avgDuration) if myList[
            i
        ].avgDuration else curr_perf.append(0)
        # print("cur_perf", myList[i].total_flops/myList[i].avgDuration) if myList[i].avgDuration else print("null")

        i += 1

    intensityPoints = {"ai_lds": [], "ai_l1": [], "ai_l2": [], "ai_hbm": []}
    print(intensityPoints)

    plotted_spots = []
    labels = []
    for i in intensities:
        values = intensities[i]

        color = get_color(i)
        x = []
        y = []
        for entryIndx in range(0, len(values)):
            x.append(values[entryIndx])
            y.append(curr_perf[entryIndx])

        intensityPoints[i].append(x)
        intensityPoints[i].append(y)

    # Add an entry for kernel names
    intensityPoints["kernelNames"] = kernelNames

    return intensityPoints

def empirical_roof(roof_info, mem_level, verbose):
    roofPath = roof_info["path"] + "/roofline.csv"
    # -----------------------------------------------------
    # Initialize roofline data dictionary from roofline.csv
    # -----------------------------------------------------
    roof_data = (
        {}
    )  # TODO: consider changing this to an ordered dict for consistency over py versions
    headers = []
    try:
        with open(roofPath, "r") as csvfile:
            csvReader = csv.reader(csvfile, delimiter=",")
            rowCount = 0
            for row in csvReader:
                row.pop(0)  # remove devID
                if rowCount == 0:
                    headers = row
                    for i in headers:
                        roof_data[i] = []
                else:
                    for i, key in enumerate(headers):
                        roof_data[key].append(row[i])

                rowCount += 1
        csvfile.close()
    except:
        graphPoints = {
            "hbm": [None, None, None],
            "l2": [None, None, None],
            "l1": [None, None, None],
            "lds": [None, None, None],
            "valu": [None, None, None],
            "mfma": [None, None, None],
        }
        return graphPoints

    # ------------------
    #  Generate Roofline
    # ------------------
    results = plot_roof(roof_info, roof_data, mem_level, verbose)
    # for key in results:
    #     print(key, "->", results[key])

    return results

##### Change this to the folder name where your omniperf CSV files are located #####
OMNIPERF_DB_FOLDER_NAME='MY_OMNIPERF_FOLDER'

t_df = OrderedDict()
t_df["pmc_perf"] = pd.read_csv(os.path.join(OMNIPERF_DB_BASE, OMNIPERF_DB_FOLDER_NAME, PMC_PERF_FILE))
get_roofline(os.path.join(OMNIPERF_DB_BASE, OMNIPERF_DB_FOLDER_NAME), t_df, 3, "ALL", "kernels", "ALL", True, True)